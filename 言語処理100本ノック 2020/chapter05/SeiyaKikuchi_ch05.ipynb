{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ai.ja.zip\n",
    "#!cabocha -f1ai.ja.txt > ai_ja_cabocha.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40.係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph():\n",
    "    def __init__(self, l):\n",
    "        info = l[1].split(',')\n",
    "        self.surface = l[0]\n",
    "        self.base = info[6]\n",
    "        self.pos = info[0]\n",
    "        self.pos1 = info[1]\n",
    "    def __str__(self):\n",
    "        #return f'{self.surface} ({self.base}/{self.pos}/{self.pos1})'\n",
    "        return f'{self.surface}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 -1D 1/1 0.000000\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "EOS\n",
      "EOS\n",
      "* 0 17D 1/1 0.388993\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "* 1 17D 2/3 0.613549\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 /Users/seiya.k/workspace/100knock-2020/SeiyaKikuchi/chapter05/work/ai_ja_cabocha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/seiya.k/workspace/100knock-2020/SeiyaKikuchi/chapter05/work/ai_ja_cabocha.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人工',\n",
      " '知能',\n",
      " '（',\n",
      " 'じん',\n",
      " 'こうち',\n",
      " 'のう',\n",
      " '、',\n",
      " '、',\n",
      " 'AI',\n",
      " '〈',\n",
      " 'エーアイ',\n",
      " '〉',\n",
      " '）',\n",
      " 'と',\n",
      " 'は',\n",
      " '、',\n",
      " '「',\n",
      " '『',\n",
      " '計算',\n",
      " '（',\n",
      " '）',\n",
      " '』',\n",
      " 'という',\n",
      " '概念',\n",
      " 'と',\n",
      " '『',\n",
      " 'コンピュータ',\n",
      " '（',\n",
      " '）',\n",
      " '』',\n",
      " 'という',\n",
      " '道具',\n",
      " 'を',\n",
      " '用い',\n",
      " 'て',\n",
      " '『',\n",
      " '知能',\n",
      " '』',\n",
      " 'を',\n",
      " '研究',\n",
      " 'する',\n",
      " '計算',\n",
      " '機',\n",
      " '科学',\n",
      " '（',\n",
      " '）',\n",
      " 'の',\n",
      " '一',\n",
      " '分野',\n",
      " '」',\n",
      " 'を',\n",
      " '指す',\n",
      " '語',\n",
      " '。',\n",
      " '「',\n",
      " '言語',\n",
      " 'の',\n",
      " '理解',\n",
      " 'や',\n",
      " '推論',\n",
      " '、',\n",
      " '問題',\n",
      " '解決',\n",
      " 'など',\n",
      " 'の',\n",
      " '知的',\n",
      " '行動',\n",
      " 'を',\n",
      " '人間',\n",
      " 'に',\n",
      " '代わっ',\n",
      " 'て',\n",
      " 'コンピューター',\n",
      " 'に',\n",
      " '行わ',\n",
      " 'せる',\n",
      " '技術',\n",
      " '」',\n",
      " '、',\n",
      " 'または',\n",
      " '、',\n",
      " '「',\n",
      " '計算',\n",
      " '機',\n",
      " '（',\n",
      " 'コンピュータ',\n",
      " '）',\n",
      " 'による',\n",
      " '知的',\n",
      " 'な',\n",
      " '情報処理',\n",
      " 'システム',\n",
      " 'の',\n",
      " '設計',\n",
      " 'や',\n",
      " '実現',\n",
      " 'に関する',\n",
      " '研究',\n",
      " '分野',\n",
      " '」',\n",
      " 'と',\n",
      " 'も',\n",
      " 'さ',\n",
      " 'れる',\n",
      " '。']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "with open(path) as f:\n",
    "    sentence = []\n",
    "    \n",
    "    for l in f:\n",
    "        l = l.strip().split('\\t')\n",
    "        if len(l) == 1:\n",
    "            if l[0] == 'EOS':\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            morph = Morph(l)\n",
    "            sentence.append(morph)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint([str(m) for m in sentences[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 41.係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk():\n",
    "    def __init__(self, morphs, dst, srcs, idx):\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = srcs\n",
    "        self.idx = idx\n",
    "    def __str__(self):\n",
    "        return ''.join([str(m) for m in self.morphs])\n",
    "        #+ ' ' + str(self.dst) + '/' + str(self.srcs) + '/' + str(self.idx)\n",
    "        #return f'{self.morphs} (d:{self.dst}/s:{self.srcs})'\n",
    "    def return_m_list(self):\n",
    "        return list([str(m) for m in self.morphs])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人工知能',\n",
      " '（じんこうちのう、、',\n",
      " 'AI',\n",
      " '〈エーアイ〉）とは、',\n",
      " '「『計算',\n",
      " '（）』という',\n",
      " '概念と',\n",
      " '『コンピュータ',\n",
      " '（）』という',\n",
      " '道具を',\n",
      " '用いて',\n",
      " '『知能』を',\n",
      " '研究する',\n",
      " '計算機科学',\n",
      " '（）の',\n",
      " '一分野」を',\n",
      " '指す',\n",
      " '語。',\n",
      " '「言語の',\n",
      " '理解や',\n",
      " '推論、',\n",
      " '問題解決などの',\n",
      " '知的行動を',\n",
      " '人間に',\n",
      " '代わって',\n",
      " 'コンピューターに',\n",
      " '行わせる',\n",
      " '技術」、または、',\n",
      " '「計算機',\n",
      " '（コンピュータ）による',\n",
      " '知的な',\n",
      " '情報処理システムの',\n",
      " '設計や',\n",
      " '実現に関する',\n",
      " '研究分野」とも',\n",
      " 'される。']\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "sentences_q41 = []\n",
    "with open(path) as f:\n",
    "    morphs = []\n",
    "    sentence = []\n",
    "    dsts = []\n",
    "    dst, srcs = -999, -999\n",
    "    \n",
    "    for l in f:\n",
    "        l = l.strip().split('\\t')\n",
    "        \n",
    "        if l[0] == 'EOS':\n",
    "            if dst != -999 and srcs != -999:\n",
    "                chunk = Chunk(morphs, dst, srcs, chunk_id)\n",
    "                sentence.append(chunk)\n",
    "                morphs = []\n",
    "                dst, srcs = 999, 999\n",
    "            if sentence == []:\n",
    "                pass\n",
    "            sentences_q41.append(sentence)\n",
    "            sentence = []\n",
    "            #print(dsts)\n",
    "            dsts = []\n",
    "                \n",
    "        elif len(l[0].split(' ')) == 5:\n",
    "            if morphs != [] and dst != 999 and srcs != 999:\n",
    "                chunk = Chunk(morphs, dst, srcs, chunk_id)\n",
    "                sentence.append(chunk)\n",
    "                morphs = []\n",
    "                dst, srcs = -999, -999\n",
    "                \n",
    "            nums = l[0].split(' ')\n",
    "            dst, chunk_id = int(nums[2][:-1]), int(nums[1])\n",
    "            dsts.append(dst)\n",
    "            \n",
    "            srcs = []\n",
    "            for i, d in enumerate(dsts, 1):\n",
    "                if chunk_id == d:\n",
    "                    srcs.append(i)                \n",
    "                        \n",
    "        else:\n",
    "            morph = Morph(l)\n",
    "            morphs.append(morph)\n",
    "            \n",
    "from pprint import pprint\n",
    "pprint(([str(c) for c in sentences_q41[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 今回の処理結果はgroupbyを使えば「１文あたり」のイテレータにできる\n",
    "### Chunkのself.morphs部分をMorphから継承すればいいじゃないか\n",
    "### infoをsplitしてMorphに格納する処理はクラス内に収めてしまえ\n",
    "### デフォルト値を設定するメソッドとかありそう...（マイナスの値にすること）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 42.係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能\t語。\n",
      "（じんこうちのう、、\t語。\n",
      "AI\t〈エーアイ〉）とは、\n",
      "〈エーアイ〉）とは、\t語。\n",
      "「『計算\t（）』という\n",
      "（）』という\t道具を\n",
      "概念と\t道具を\n",
      "『コンピュータ\t（）』という\n",
      "（）』という\t道具を\n",
      "道具を\t用いて\n",
      "用いて\t研究する\n",
      "『知能』を\t研究する\n",
      "研究する\t計算機科学\n",
      "計算機科学\t（）の\n",
      "（）の\t一分野」を\n",
      "一分野」を\t指す\n",
      "指す\t語。\n",
      "語。\t研究分野」とも\n",
      "「言語の\t推論、\n",
      "理解や\t推論、\n",
      "推論、\t問題解決などの\n",
      "問題解決などの\t知的行動を\n",
      "知的行動を\t代わって\n",
      "人間に\t代わって\n",
      "代わって\t行わせる\n",
      "コンピューターに\t行わせる\n",
      "行わせる\t技術」、または、\n",
      "技術」、または、\t研究分野」とも\n",
      "「計算機\t（コンピュータ）による\n",
      "（コンピュータ）による\t情報処理システムの\n",
      "知的な\t情報処理システムの\n",
      "情報処理システムの\t実現に関する\n",
      "設計や\t実現に関する\n",
      "実現に関する\t研究分野」とも\n",
      "研究分野」とも\tされる。\n"
     ]
    }
   ],
   "source": [
    "id_text_pair = [(i, c) for i, c in enumerate(sentences_q41[2])]\n",
    "\n",
    "for c in sentences_q41[2]:\n",
    "    for pair in id_text_pair:\n",
    "        if c.dst == pair[0]:\n",
    "            print(f'{c}\\t{pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 句読点は出力しない(関数を追加しないと)\n",
    "### 文節にidを振る処理はQ41で済ませてしまっていい\n",
    "### 1文字変数の使用はfor文内に留め、なるべく意味のある変数名を使うこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 43.名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道具を\t用いて\n",
      "『知能』を\t研究する\n",
      "一分野」を\t指す\n",
      "知的行動を\t代わって\n",
      "人間に\t代わって\n",
      "コンピューターに\t行わせる\n",
      "研究分野」とも\tされる。\n"
     ]
    }
   ],
   "source": [
    "id_text_pair = [(i, c) for i, c in enumerate(sentences_q41[2])]\n",
    "\n",
    "for c in sentences_q41[2]:\n",
    "    if any([m.pos == '名詞' for m in c.morphs]):\n",
    "        for pair in id_text_pair:\n",
    "            if c.dst == pair[0]:\n",
    "                if any([m.pos == '動詞' for m in pair[1].morphs]):\n",
    "                    print(f'{c}\\t{pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 44.係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"655pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 654.89 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-328 650.8916,-328 650.8916,4 -4,4\"/>\n",
       "<!-- 1956年に -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1956年に</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"56.545\" cy=\"-306\" rx=\"47.3916\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.545\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1956年に</text>\n",
       "</g>\n",
       "<!-- 行われた、 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>行われた、</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"56.545\" cy=\"-234\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.545\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">行われた、</text>\n",
       "</g>\n",
       "<!-- 1956年に&#45;&gt;行われた、 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1956年に&#45;&gt;行われた、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M56.545,-287.8314C56.545,-280.131 56.545,-270.9743 56.545,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.0451,-262.4132 56.545,-252.4133 53.0451,-262.4133 60.0451,-262.4132\"/>\n",
       "</g>\n",
       "<!-- 提案書において、 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>提案書において、</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"233.545\" cy=\"-162\" rx=\"83.6854\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.545\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">提案書において、</text>\n",
       "</g>\n",
       "<!-- 行われた、&#45;&gt;提案書において、 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>行われた、&#45;&gt;提案書において、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.5145,-219.7751C118.242,-208.9029 155.4033,-193.7864 185.0105,-181.7428\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.3909,-184.9599 194.335,-177.9498 183.7532,-178.4758 186.3909,-184.9599\"/>\n",
       "</g>\n",
       "<!-- 使用され、 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>使用され、</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"438.545\" cy=\"-90\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.545\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">使用され、</text>\n",
       "</g>\n",
       "<!-- 提案書において、&#45;&gt;使用され、 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>提案書において、&#45;&gt;使用され、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277.5226,-146.5542C310.8239,-134.8581 356.5192,-118.8091 390.7262,-106.7949\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"392.2222,-109.9791 400.4974,-103.3631 389.9026,-103.3746 392.2222,-109.9791\"/>\n",
       "</g>\n",
       "<!-- ダートマス会議開催の -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ダートマス会議開催の</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"233.545\" cy=\"-234\" rx=\"102.0819\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.545\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ダートマス会議開催の</text>\n",
       "</g>\n",
       "<!-- ダートマス会議開催の&#45;&gt;提案書において、 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>ダートマス会議開催の&#45;&gt;提案書において、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.545,-215.8314C233.545,-208.131 233.545,-198.9743 233.545,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.0451,-190.4132 233.545,-180.4133 230.0451,-190.4133 237.0451,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 創立された。 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>創立された。</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"503.545\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"503.545\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">創立された。</text>\n",
       "</g>\n",
       "<!-- 使用され、&#45;&gt;創立された。 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>使用され、&#45;&gt;創立された。</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M454.2797,-72.5708C462.2843,-63.7041 472.1574,-52.7678 480.9581,-43.0194\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"483.6268,-45.2863 487.7299,-35.5182 478.4309,-40.5956 483.6268,-45.2863\"/>\n",
       "</g>\n",
       "<!-- 人類史上、 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>人類史上、</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"410.545\" cy=\"-234\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"410.545\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">人類史上、</text>\n",
       "</g>\n",
       "<!-- 用語として -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>用語として</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"400.545\" cy=\"-162\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.545\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">用語として</text>\n",
       "</g>\n",
       "<!-- 人類史上、&#45;&gt;用語として -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>人類史上、&#45;&gt;用語として</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M408.0216,-215.8314C406.9521,-208.131 405.6803,-198.9743 404.4917,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"407.9449,-189.8367 403.1024,-180.4133 401.0114,-190.7997 407.9449,-189.8367\"/>\n",
       "</g>\n",
       "<!-- 用語として&#45;&gt;使用され、 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>用語として&#45;&gt;使用され、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M409.9382,-144.2022C414.2772,-135.981 419.5233,-126.041 424.3318,-116.9301\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.5558,-118.3201 429.1281,-107.8425 421.3651,-115.0527 427.5558,-118.3201\"/>\n",
       "</g>\n",
       "<!-- 初めて -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>初めて</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"513.545\" cy=\"-162\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"513.545\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">初めて</text>\n",
       "</g>\n",
       "<!-- 初めて&#45;&gt;使用され、 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>初めて&#45;&gt;使用され、</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M496.5263,-145.6621C486.9276,-136.4474 474.7464,-124.7534 464.0293,-114.4649\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"466.1799,-111.6778 456.5421,-107.2773 461.3322,-116.7275 466.1799,-111.6778\"/>\n",
       "</g>\n",
       "<!-- 新たな -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>新たな</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"608.545\" cy=\"-162\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.545\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">新たな</text>\n",
       "</g>\n",
       "<!-- 分野として -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>分野として</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"588.545\" cy=\"-90\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"588.545\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">分野として</text>\n",
       "</g>\n",
       "<!-- 新たな&#45;&gt;分野として -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>新たな&#45;&gt;分野として</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M603.4981,-143.8314C601.3356,-136.0463 598.7597,-126.7729 596.3602,-118.1347\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"599.7086,-117.1117 593.6598,-108.4133 592.964,-118.9852 599.7086,-117.1117\"/>\n",
       "</g>\n",
       "<!-- 分野として&#45;&gt;創立された。 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>分野として&#45;&gt;創立された。</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M568.4012,-72.937C557.4718,-63.6792 543.785,-52.0857 531.805,-41.9379\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"533.7315,-38.9828 523.8388,-35.19 529.207,-44.3242 533.7315,-38.9828\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe259edb5d0>"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph(comment='chunk tree')\n",
    "\n",
    "id_text_pair = [(i, c) for i, c in enumerate(sentences_q41[26])]\n",
    "\n",
    "for c in sentences_q41[26]:\n",
    "    for pair in id_text_pair:\n",
    "        \n",
    "        if c.dst == pair[0]:\n",
    "            # nodeに随時ラベルを貼らないと、同じ文字表記の文節を同じnodeとして扱ってしまう。\n",
    "            dot.node(str(c))\n",
    "            dot.node(str(pair[1]))\n",
    "            dot.edge(str(c), str(pair[1]))\n",
    "\n",
    "# print(dot.source) \n",
    "# dot.render('/Users/seiya.k/workspace/100knock-2020/SeiyaKikuchi/chapter05/work/graph_q44.gv', view=True)\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodeに随時ラベルを貼らないと、同じ文字表記の文節を同じnodeとして扱ってしまう。(「という」が１つのnodeにまとまっている)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45.動詞の格パターンの抽出  \n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "動詞を含む文節において，最左の動詞の基本形を述語とする  \n",
    "述語に係る助詞を格とする  \n",
    "述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる  \n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "作り出す\tで は を  \n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = 'work/Q45_corpus.txt'\n",
    "\n",
    "with open(new_file,\"w\") as f:\n",
    "    for sentence in sentences_q41:\n",
    "        for c in sentence:\n",
    "            if any([m.pos == '動詞' for m in c.morphs]) and c.srcs != []:\n",
    "                case = ''\n",
    "                for src in c.srcs:\n",
    "                    for m in sentence[src].morphs:\n",
    "                        if m.pos == '助詞':\n",
    "                            case += m.base + ' '\n",
    "                if case != '':\n",
    "                    for m in c.morphs:\n",
    "                        if m.pos == '動詞':\n",
    "                            f.write(m.base + '\\t')\n",
    "                            f.write(case + '\\n')\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tて \n",
      "する\tを \n",
      "代わる\tに て \n",
      "行う\tに \n",
      "述べる\tの の に て \n"
     ]
    }
   ],
   "source": [
    "!head -n 5 work/Q45_corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16 する\tの \n",
      "  16 する\tて \n",
      "  14 する\tに \n",
      "   8 する\tの て \n",
      "   8 する\tを \n"
     ]
    }
   ],
   "source": [
    "!sort work/Q45_corpus.txt | uniq -c | sort -r | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3 行う\tに を \n",
      "   3 行う\tて \n",
      "   2 行う\tを て \n",
      "   1 行う\tなど \n",
      "   1 行う\tが という \n"
     ]
    }
   ],
   "source": [
    "!grep \"^行う\\t\" work/Q45_corpus.txt | sort | uniq -c | sort -r | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 なる\tと \n",
      "   2 なる\tの \n",
      "   1 なる\tに関する が を と て \n",
      "   1 なる\tにとって と \n",
      "   1 なる\tから で は が の \n"
     ]
    }
   ],
   "source": [
    "!grep \"^なる\\t\" work/Q45_corpus.txt | sort | uniq -c | sort -r | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 与える\tなど に \n",
      "   1 与える\tに として も \n",
      "   1 与える\tの を \n"
     ]
    }
   ],
   "source": [
    "!grep \"^与える\\t\" work/Q45_corpus.txt | sort | uniq -c | sort -r | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46.動詞の格フレーム情報の抽出  \n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）  \n",
    "述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる  \n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "作り出す\tで は を\t会議で ジョンマッカーシーは 用語を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = 'work/Q46.txt'\n",
    "\n",
    "with open(new_file,\"w\") as f:\n",
    "    for sentence in sentences_q41:\n",
    "        for c in sentence:\n",
    "            if any([m.pos == '動詞' for m in c.morphs]) and c.srcs != []:\n",
    "                case = ''\n",
    "                para = ''\n",
    "                for src in c.srcs:\n",
    "                    para += str(sentence[src]) + ' '\n",
    "                    for m in sentence[src].morphs:\n",
    "                        if m.pos == '助詞':\n",
    "                            case += m.base + ' '\n",
    "                if case != '':\n",
    "                    for m in c.morphs:\n",
    "                        if m.pos == '動詞':\n",
    "                            f.write(m.base + '\\t' + case + para + '\\n')\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tて 用いて \n",
      "する\tを 『知能』を 研究する \n",
      "代わる\tに て 人間に 代わって \n",
      "行う\tに コンピューターに 行わせる \n",
      "述べる\tの の に て 情報工学者・通信工学者の 次のように 述べている。 \n",
      "する\tで コンピュータ上で 実現する、 \n",
      "する\tて 解析して \n",
      "する\tの たり 特定の 検出・抽出したりする \n",
      "ある\tは 応用例は 自然言語処理 ある。 \n",
      "する\tに で により 1956年に ダートマス会議で ジョン・マッカーシーにより 命名された。 \n"
     ]
    }
   ],
   "source": [
    "!head work/Q46.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 項を辞書順にsortしてない\n",
    "### 空文字列\"\"を条件節に持ってくるのはあんまり見ない。空リストはアリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 47.機能動詞構文のマイニング  \n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる  \n",
    "述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）  \n",
    "例えば「また、自らの経験を元に学習を行う強化学習という手法もある。」という文から，以下の出力が得られるはずである．  \n",
    "\n",
    "学習を行う\tに を\t元に 経験を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = 'work/Q47.txt'\n",
    "\n",
    "with open(new_file,\"w\") as f:\n",
    "    for sentence in sentences_q41:\n",
    "        for c in sentence:\n",
    "            if any([m.pos == '動詞' for m in c.morphs]) and c.srcs != []:\n",
    "                predicate = []\n",
    "                para_and_case = dict()\n",
    "                for src in c.srcs:\n",
    "                    for i, m in enumerate(sentence[src].morphs):\n",
    "                        if m.pos == '助詞':\n",
    "                            para_and_case[str(sentence[src])] = str(sentence[src].morphs[i].base)\n",
    "                        elif m.pos１ == 'サ変接続' and sentence[src].morphs[i-1].surface == 'を':\n",
    "                            predicate.extend(m.base + sentence[src].morphs[i-1].base)\n",
    "                if predicate != []:\n",
    "                    for m in c.morphs:\n",
    "                        if m.pos == '動詞':\n",
    "                            predicate.extend(m.base)\n",
    "                            sorted_dic = sorted(para_and_case.items(), key=lambda x: x[0])\n",
    "                            f.write(''.join(predicate) + '\\t'+ ' '.join([t[1] for t in sorted_dic]) + '\\t'+ ' '.join([str(t[0]) for t in sorted_dic]) + '\\n')\n",
    "                            para_and_case = None\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注目を集める\tが を\t「サポートベクターマシン」が 注目を\n",
      "学習を行う\tに を\t元に 学習を\n",
      "統計をする\tは の や に を\tACT-Rでは、 エキスパートの ニューラルネットワークや 元に 統計的学習を\n",
      "プログラミングをする\tを は\tプログラミング言語を 彼はまた\n",
      "プログラミングをする\tは を と\tアラン・カルメラウアーは プログラミング言語を マービン・ミンスキーと\n",
      "処理を行う\tを\t処理を\n",
      "意味をする\tて を\t付加して、 意味を\n",
      "運転をする\tを\t運転を\n",
      "運転をする\tに を\t柔軟に 運転を\n",
      "開発をある\tの の を\t人間の 従来の 開発工数を\n",
      "表現をする\tを として\t表現する）を （ファジィルールとして\n",
      "研究を続ける\tに を が\t実現に 研究を 続けているが、\n",
      "共同を始める\tの を て\tドイツの 共同研究を 始めており、\n",
      "投資をする\tを を\t20億ドルを 投資を\n",
      "反乱を起こす\tに対して を\t人間に対して 反乱を\n",
      "監視を行う\tと に を\tネット検閲と 人工知能に 監視を\n",
      "監視をする\tと に と を は\t中国本土と 市民に 次々と 監視カメラを 香港では、\n",
      "戦争をなる\tの の を の\tなるとの 大国間の 戦争を 軍の\n",
      "追及を受ける\tが は を に を\tGoogleが アメリカでは 人工知能を 同様に 追及を\n",
      "解任をする\tは は を\tGoogle社員らは 倫理委員会には 解任を\n",
      "議論を行う\tて を\t行ってきました。 議論を\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 work/Q47.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 48.名詞から根へのパスの抽出\n",
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "各文節は（表層形の）形態素列で表現する  \n",
    "パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する  \n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．  \n",
    "\n",
    "ジョンマッカーシーは -> 作り出した  \n",
    "AIに関する -> 最初の -> 会議で -> 作り出した  \n",
    "最初の -> 会議で -> 作り出した  \n",
    "会議で -> 作り出した  \n",
    "人工知能という -> 用語を -> 作り出した  \n",
    "用語を -> 作り出した  \n",
    "KNPを係り受け解析に用いた場合，次のような出力が得られると思われる．  \n",
    "\n",
    "ジョンマッカーシーは -> 作り出した  \n",
    "ＡＩに -> 関する -> 会議で -> 作り出した  \n",
    "会議で -> 作り出した  \n",
    "人工知能と -> いう -> 用語を -> 作り出した  \n",
    "用語を -> 作り出した  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956年に -> 行われた、 -> 提案書において、 -> 使用され、 -> 創立された。\n",
      "ダートマス会議開催の -> 提案書において、 -> 使用され、 -> 創立された。\n",
      "提案書において、 -> 使用され、 -> 創立された。\n",
      "人類史上、 -> 用語として -> 使用され、 -> 創立された。\n",
      "用語として -> 使用され、 -> 創立された。\n",
      "使用され、 -> 創立された。\n",
      "新たな -> 分野として -> 創立された。\n",
      "分野として -> 創立された。\n",
      "創立された。\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences_q41[26]\n",
    "for c in sentence:\n",
    "    if any([m.pos == '名詞' for m in c.morphs]):\n",
    "        path_q48 = [str(c)]\n",
    "        dst = c.dst\n",
    "        while dst != -1:\n",
    "            path_q48.append(' -> ' + str(sentence[dst]))\n",
    "            dst = sentence[dst].dst\n",
    "        print(''.join(path_q48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 49.名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．  \n",
    "\n",
    "問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する  \n",
    "文節iとjに含まれる名詞句はそれぞれ，XとYに置換する  \n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．  \n",
    "\n",
    "文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示  \n",
    "上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示  \n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair_of_noun_phrase(sentence):\n",
    "    noun_phrases = []\n",
    "    for c in sentence:\n",
    "        if any([m.pos == '名詞' for m in c.morphs]):\n",
    "            noun_phrases.append(c)\n",
    "            #noun_phrases.append(str(c))\n",
    "    np_pairs = itertools.combinations(noun_phrases, 2)\n",
    "    #print([i for i in np_pairs])\n",
    "    return np_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_noun_to_X(chunk):\n",
    "    new_np = []\n",
    "    first = True\n",
    "    for m in chunk.morphs:\n",
    "        if m.pos == '名詞':\n",
    "            if first:\n",
    "                new_np.append('X')\n",
    "                first = False\n",
    "            else:\n",
    "                new_np.append(str(m))\n",
    "        else:\n",
    "            new_np.append(str(m))\n",
    "    new_np = ''.join(new_np)\n",
    "    return new_np\n",
    "\n",
    "def change_noun_to_Y(chunk):\n",
    "    new_np = []\n",
    "    first = True\n",
    "    for m in chunk.morphs:\n",
    "        if m.pos == '名詞':\n",
    "            if first:\n",
    "                new_np.append('Y')\n",
    "                first = False\n",
    "            else:\n",
    "                new_np.append(str(m))\n",
    "        else:\n",
    "            new_np.append(str(m))\n",
    "    new_np = ''.join(new_np)\n",
    "    return new_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "『日本大百科全書(ニッポニカ)』の解説で、情報工学者・通信工学者の佐藤理史は次のように述べている。\n",
      "--------------\n",
      " # 『日本大百科全書(ニッポニカ)』の -> 解説で、\n",
      "『X大百科全書(ニッポニカ)』の -> Yで、\n",
      " # 『日本大百科全書(ニッポニカ)』の -> 情報工学者・通信工学者の\n",
      "『X大百科全書(ニッポニカ)』の -> 解説で、 | Y工学者・通信工学者の -> 佐藤理史は |  -> 述べている。\n",
      " # 『日本大百科全書(ニッポニカ)』の -> 佐藤理史は\n",
      "『X大百科全書(ニッポニカ)』の -> 解説で、 | Y理史は |  -> 述べている。\n",
      " # 『日本大百科全書(ニッポニカ)』の -> 次のように\n",
      "『X大百科全書(ニッポニカ)』の -> 解説で、 | Yのように |  -> 述べている。\n",
      " # 解説で、 -> 情報工学者・通信工学者の\n",
      "Xで、 | Y工学者・通信工学者の -> 佐藤理史は |  -> 述べている。\n",
      " # 解説で、 -> 佐藤理史は\n",
      "Xで、 | Y理史は |  -> 述べている。\n",
      " # 解説で、 -> 次のように\n",
      "Xで、 | Yのように |  -> 述べている。\n",
      " # 情報工学者・通信工学者の -> 佐藤理史は\n",
      "X工学者・通信工学者の -> Y理史は\n",
      " # 情報工学者・通信工学者の -> 次のように\n",
      "X工学者・通信工学者の -> 佐藤理史は | Yのように |  -> 述べている。\n",
      " # 佐藤理史は -> 次のように\n",
      "X理史は | Yのように |  -> 述べている。\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "sentence = sentences_q41[4]\n",
    "noun_phrases = []\n",
    "\n",
    "print(''.join([str(c) for c in sentence]) + '\\n' + '--------------')\n",
    "\n",
    "for pair in create_pair_of_noun_phrase(sentence):\n",
    "    #print(str(pair[0]), pair[0].idx, str(pair[1]), pair[1].idx)\n",
    "    print(' #', str(pair[0]), '->', str(pair[1]))\n",
    "    \n",
    "    path_q49 = [change_noun_to_X(pair[0])]\n",
    "    dst = pair[0].dst\n",
    "    first = True\n",
    "    \n",
    "    while dst != -1:\n",
    "        \n",
    "        if dst > pair[1].idx and first:\n",
    "            path_q49.append(' | ' + change_noun_to_Y(pair[1]))\n",
    "            branched_dst = pair[1].dst\n",
    "            \n",
    "            while branched_dst != dst:\n",
    "                path_q49.append(' -> ' + str(sentence[branched_dst]))\n",
    "                branched_dst = sentence[branched_dst].dst\n",
    "                \n",
    "            path_q49.append(' | ')\n",
    "            dst = branched_dst\n",
    "            first = False\n",
    "                            \n",
    "        elif dst == pair[1].idx:\n",
    "            path_q49.append(' -> ' + change_noun_to_Y(sentence[dst]))\n",
    "            dst = sentence[dst].dst\n",
    "            break\n",
    "            \n",
    "        path_q49.append(' -> ' + str(sentence[dst]))\n",
    "        dst = sentence[dst].dst\n",
    "            \n",
    "    print(''.join(path_q49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
